{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 安裝成功，版本: 1.12.1\n",
      "CUDA 可用\n",
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.__version__:\n",
    "    print(\"PyTorch 安裝成功，版本:\", torch.__version__)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA 可用\")\n",
    "        print(torch.cuda.get_device_name())\n",
    "    else:\n",
    "        print(\"CUDA 不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "## Training set has 100 instances.\n",
      "## Validation set has 10 instances.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "# Create dataset(use 100 data for my laptop)\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "valid_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "train_set = Subset(train_set, list(range(100)))\n",
    "valid_set = Subset(valid_set, list(range(100, 110)))\n",
    "\n",
    "# Create data loaders for our datasets\n",
    "train_loader = DataLoader(train_set, batch_size=5, shuffle=False)\n",
    "valid_loader = DataLoader(valid_set, batch_size=5, shuffle=False)\n",
    "\n",
    "print(f'## Training set has {len(train_set)} instances.')\n",
    "print(f'## Validation set has {len(valid_set)} instances.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\", progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function(Criterion) & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    sum_loss, sum_acc = 0.0, 0.0\n",
    "    running_loss,running_acc = 0.0, 0.0\n",
    "    last_loss, last_acc = 0.0, 0.0\n",
    "\n",
    "    START_TIME = time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        sum_loss += loss.item()\n",
    "        running_acc += accuracy_score(labels, outputs.argmax(dim=1))\n",
    "        sum_acc += accuracy_score(labels, outputs.argmax(dim=1))\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss/10\n",
    "            last_acc = running_acc/10\n",
    "            # print(f' - Batch {i+1} loss: {last_loss:.4f} / accuracy: {last_acc:.4f}')\n",
    "\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "    END_TIME = time()\n",
    "\n",
    "    count = len(train_loader.dataset)\n",
    "    return sum_loss/count, sum_acc/count, (END_TIME-START_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: Train Loss: 0.0003 / Valid Loss: 4.8894 / Train Accuracy: 0.2000 / Valid Accuracy: 0.1000 (5.6800 sec)\n",
      "EPOCH 2: Train Loss: 0.0003 / Valid Loss: 4.8472 / Train Accuracy: 0.2000 / Valid Accuracy: 0.2000 (5.7326 sec)\n",
      "EPOCH 3: Train Loss: 0.0003 / Valid Loss: 4.8607 / Train Accuracy: 0.2000 / Valid Accuracy: 0.2000 (5.6158 sec)\n",
      "EPOCH 4: Train Loss: 0.0002 / Valid Loss: 4.8811 / Train Accuracy: 0.2000 / Valid Accuracy: 0.2000 (5.7002 sec)\n",
      "EPOCH 5: Train Loss: 0.0002 / Valid Loss: 4.9006 / Train Accuracy: 0.2000 / Valid Accuracy: 0.2000 (5.6514 sec)\n",
      "== Total time: 28.37998080253601\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/resnet18_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "total_time = 0\n",
    "EPOCHS = 5\n",
    "best_vloss = 1_000_000.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number+1}: ', end=\"\")\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, avg_acc, train_time = train_one_epoch(epoch_number, writer)\n",
    "    total_time += train_time\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(valid_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels) # current batch valid loss\n",
    "            vacc = accuracy_score(vlabels, voutputs.argmax(dim=1)) # current batch valid accuracy\n",
    "            running_vloss += vloss\n",
    "            running_vacc += vacc\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    print(f'Train Loss: {avg_loss:.4f} / Valid Loss: {avg_vloss:.4f} / '\n",
    "      f'Train Accuracy: {avg_acc:.4f} / Valid Accuracy: {avg_vacc:.4f} ({train_time:.4f} sec)')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_model = model\n",
    "        best_vloss = avg_vloss\n",
    "\n",
    "    epoch_number += 1\n",
    "print(f'== Total time: {total_time:.4f}')\n",
    "model_path = f'models/model_renet18_{timestamp}_{epoch_number}.pth'\n",
    "torch.save(best_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打不開阿!!!\n",
    "# !tensorboard --logdir runs/resnet18_trainer_20241222_125827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a saved version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"models\\model_renet18_20241222_141355_4.pth\"\n",
    "saved_model = models.resnet18()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
