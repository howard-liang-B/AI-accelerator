{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\YOLOv8_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    device = \"cuda\"\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Use CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "## Training set has 60 instances.\n",
      "## Validation set has 40 instances.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "# Create dataset(use 100 data for my laptop)\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "valid_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "train_set = Subset(train_set, list(range(0, 60)))\n",
    "valid_set = Subset(valid_set, list(range(60, 100)))\n",
    "\n",
    "# Create data loaders for our datasets\n",
    "train_loader = DataLoader(train_set, batch_size=5, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=5, shuffle=True)\n",
    "\n",
    "print(f'## Training set has {len(train_set)} instances.')\n",
    "print(f'## Validation set has {len(valid_set)} instances.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\", progress=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function(Criterion) & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    sum_loss, sum_acc = 0.0, 0.0\n",
    "    running_loss,running_acc = 0.0, 0.0\n",
    "    last_loss, last_acc = 0.0, 0.0\n",
    "\n",
    "    START_TIME = time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        sum_loss += loss\n",
    "        running_acc += accuracy_score(labels.cpu(), outputs.argmax(dim=1).cpu())\n",
    "        sum_acc += accuracy_score(labels.cpu(), outputs.argmax(dim=1).cpu())\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss/10\n",
    "            last_acc = running_acc/10\n",
    "            # print(f' - Batch {i+1} loss: {last_loss:.4f} / accuracy: {last_acc:.4f}')\n",
    "\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            tb_writer.add_scalar('Accuracy/train', last_acc, tb_x)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "    END_TIME = time()\n",
    "\n",
    "    return sum_loss/(i + 1), sum_acc/(i + 1), (END_TIME-START_TIME)\n",
    "\n",
    "def reset_folder():\n",
    "    shutil.rmtree(\"./models\")\n",
    "    shutil.rmtree(\"./runs\")\n",
    "    os.makedirs(\"./models\")\n",
    "    os.makedirs(\"./runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## start warm up\n",
      "## finished warm up\n",
      "EPOCH 1: Train Loss: 10.9382 / Valid Loss: 24.4397 / Train Accuracy: 0.0000 / Valid Accuracy: 0.0000 --- (0.4523 sec)\n",
      "EPOCH 2: Train Loss: 9.6092 / Valid Loss: 19.3162 / Train Accuracy: 0.0333 / Valid Accuracy: 0.0000 --- (0.2402 sec)\n",
      "EPOCH 3: Train Loss: 8.4187 / Valid Loss: 17.3648 / Train Accuracy: 0.0333 / Valid Accuracy: 0.0000 --- (0.2434 sec)\n",
      "EPOCH 4: Train Loss: 6.5943 / Valid Loss: 18.6184 / Train Accuracy: 0.0833 / Valid Accuracy: 0.0000 --- (0.2516 sec)\n",
      "EPOCH 5: Train Loss: 5.8035 / Valid Loss: 15.7417 / Train Accuracy: 0.2167 / Valid Accuracy: 0.0000 --- (0.2555 sec)\n",
      "EPOCH 6: Train Loss: 4.6363 / Valid Loss: 14.8869 / Train Accuracy: 0.2667 / Valid Accuracy: 0.0250 --- (0.2535 sec)\n",
      "EPOCH 7: Train Loss: 4.1904 / Valid Loss: 13.4575 / Train Accuracy: 0.2833 / Valid Accuracy: 0.0500 --- (0.2358 sec)\n",
      "EPOCH 8: Train Loss: 3.0560 / Valid Loss: 12.1625 / Train Accuracy: 0.4833 / Valid Accuracy: 0.0750 --- (0.2362 sec)\n",
      "EPOCH 9: Train Loss: 2.6656 / Valid Loss: 11.3511 / Train Accuracy: 0.3833 / Valid Accuracy: 0.0750 --- (0.2672 sec)\n",
      "EPOCH 10: Train Loss: 2.5199 / Valid Loss: 12.5914 / Train Accuracy: 0.5333 / Valid Accuracy: 0.1000 --- (0.2336 sec)\n",
      "EPOCH 11: Train Loss: 2.2082 / Valid Loss: 12.1328 / Train Accuracy: 0.5833 / Valid Accuracy: 0.1000 --- (0.2339 sec)\n",
      "EPOCH 12: Train Loss: 1.6263 / Valid Loss: 12.0366 / Train Accuracy: 0.6500 / Valid Accuracy: 0.1000 --- (0.2362 sec)\n",
      "EPOCH 13: Train Loss: 1.1620 / Valid Loss: 10.2920 / Train Accuracy: 0.7167 / Valid Accuracy: 0.1000 --- (0.2501 sec)\n",
      "EPOCH 14: Train Loss: 1.2671 / Valid Loss: 10.2931 / Train Accuracy: 0.7667 / Valid Accuracy: 0.1500 --- (0.2332 sec)\n",
      "EPOCH 15: Train Loss: 1.5038 / Valid Loss: 10.0030 / Train Accuracy: 0.6667 / Valid Accuracy: 0.1250 --- (0.2370 sec)\n",
      "EPOCH 16: Train Loss: 1.0475 / Valid Loss: 9.0869 / Train Accuracy: 0.7333 / Valid Accuracy: 0.1750 --- (0.2803 sec)\n",
      "EPOCH 17: Train Loss: 1.3506 / Valid Loss: 9.2668 / Train Accuracy: 0.7167 / Valid Accuracy: 0.1250 --- (0.2554 sec)\n",
      "EPOCH 18: Train Loss: 1.2111 / Valid Loss: 8.8052 / Train Accuracy: 0.7500 / Valid Accuracy: 0.1500 --- (0.2328 sec)\n",
      "EPOCH 19: Train Loss: 0.6934 / Valid Loss: 9.2961 / Train Accuracy: 0.8667 / Valid Accuracy: 0.1000 --- (0.2327 sec)\n",
      "EPOCH 20: Train Loss: 0.7318 / Valid Loss: 9.5207 / Train Accuracy: 0.7333 / Valid Accuracy: 0.0750 --- (0.2356 sec)\n",
      "== Total time: 5.0966 sec ==\n"
     ]
    }
   ],
   "source": [
    "reset_folder()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'runs/resnet18_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "total_time = 0\n",
    "EPOCHS = 20\n",
    "best_vloss = 1_000_000.0\n",
    "\n",
    "# warm up \n",
    "print(f'## start warm up')\n",
    "dummy_data = torch.randn(5, 3, 32, 32).to(device)\n",
    "for _ in range(500):\n",
    "    _ = model(dummy_data)\n",
    "print(f'## finished warm up')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number+1}: ', end=\"\")\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, avg_acc, train_time = train_one_epoch(epoch_number, writer)\n",
    "    total_time += train_time\n",
    "\n",
    "    # Set the model to evaluation model\n",
    "    model.eval()\n",
    "    sum_vloss = 0.0\n",
    "    sum_vacc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(valid_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels) # current batch valid loss\n",
    "            vacc = accuracy_score(vlabels.cpu(), voutputs.argmax(dim=1).cpu()) # current batch valid accuracy\n",
    "            sum_vloss += vloss.item() # running_vloss\n",
    "            sum_vacc += vacc # running_vacc\n",
    "\n",
    "    avg_vloss = sum_vloss / (i + 1)\n",
    "    avg_vacc = sum_vacc / (i + 1)\n",
    "    print(f'Train Loss: {avg_loss:.4f} / Valid Loss: {avg_vloss:.4f} / '\n",
    "          f'Train Accuracy: {avg_acc:.4f} / Valid Accuracy: {avg_vacc:.4f} --- ({train_time:.4f} sec)')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalars('Training vs. Validation Accuracy', \n",
    "                    { 'Training' : avg_acc, 'Validation': avg_vacc},\n",
    "                    epoch_number + 1)\n",
    "    writer.flush() # immediately write into file\n",
    " \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_model = model\n",
    "        best_vloss = avg_vloss\n",
    "\n",
    "    epoch_number += 1\n",
    "\n",
    "print(f'== Total time: {total_time:.4f} sec ==')\n",
    "model_path = f'models/model_renet18_{timestamp}_{epoch_number}.pth'\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a saved version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = r\"models\\model_renet18_.pth\"\n",
    "# saved_model = models.resnet18()\n",
    "# saved_model.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
