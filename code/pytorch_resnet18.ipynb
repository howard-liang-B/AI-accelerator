{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 安裝成功，版本: 1.12.1\n",
      "CUDA 可用\n",
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.__version__:\n",
    "    print(\"PyTorch 安裝成功，版本:\", torch.__version__)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA 可用\")\n",
    "        print(torch.cuda.get_device_name())\n",
    "    else:\n",
    "        print(\"CUDA 不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "## Training set has 90 instances.\n",
      "## Validation set has 10 instances.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "# Create dataset(use 100 data for my laptop)\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "valid_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "train_set = Subset(train_set, list(range(90)))\n",
    "valid_set = Subset(valid_set, list(range(90, 100)))\n",
    "\n",
    "# Create data loaders for our datasets\n",
    "train_loader = DataLoader(train_set, batch_size=5, shuffle=False)\n",
    "valid_loader = DataLoader(valid_set, batch_size=5, shuffle=False)\n",
    "\n",
    "print(f'## Training set has {len(train_set)} instances.')\n",
    "print(f'## Validation set has {len(valid_set)} instances.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\", progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function(Criterion) & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss/10\n",
    "            print(f'   Batch {i+1} loss: {last_loss}')\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.0\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== EPOCH 1 ==\n",
      "   Batch 10 loss: 0.7376733273267746\n",
      "== Train Loss: 0.7376733273267746 / Valid Loss: 3.8031139373779297\n",
      "== EPOCH 2 ==\n",
      "   Batch 10 loss: 0.6659890800714493\n",
      "== Train Loss: 0.6659890800714493 / Valid Loss: 4.150353908538818\n",
      "== EPOCH 3 ==\n",
      "   Batch 10 loss: 0.46372426897287367\n",
      "== Train Loss: 0.46372426897287367 / Valid Loss: 4.364117622375488\n",
      "== EPOCH 4 ==\n",
      "   Batch 10 loss: 0.46563472002744677\n",
      "== Train Loss: 0.46563472002744677 / Valid Loss: 4.529588222503662\n",
      "== EPOCH 5 ==\n",
      "   Batch 10 loss: 0.9611490845680237\n",
      "== Train Loss: 0.9611490845680237 / Valid Loss: 3.0714406967163086\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/resnet18_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "best_vloss = 1_000_000.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'== EPOCH {epoch_number+1} ==')\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(valid_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(f'== Train Loss: {avg_loss} / Valid Loss: {avg_vloss}')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'models/model_renet18_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 打不開阿!!!\n",
    "!tensorboard --logdir runs/resnet18_trainer_20241222_125827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a saved version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"C:\\Users\\user\\Desktop\\AI加速\\code\\weights\\model_renet18_20241222_125827_4\"\n",
    "saved_model = models.resnet18()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
