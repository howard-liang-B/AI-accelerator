{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    device = \"cuda\"\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Use CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "## Training set has 70 instances.\n",
      "## Validation set has 30 instances.\n"
     ]
    }
   ],
   "source": [
    "# train 只有 ToTensor()、Normalize()，會發生 overfit，Valid 無法收斂\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "# Create dataset(use 100 data for my laptop)\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)\n",
    "valid_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform_valid, download=True)\n",
    "train_set = Subset(train_set, list(range(0, 70)))\n",
    "valid_set = Subset(valid_set, list(range(70, 100)))\n",
    "\n",
    "# Create data loaders for our datasets\n",
    "train_loader = DataLoader(train_set, batch_size=5, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=5, shuffle=True)\n",
    "\n",
    "print(f'## Training set has {len(train_set)} instances.')\n",
    "print(f'## Validation set has {len(valid_set)} instances.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function(Criterion) & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    sum_loss, sum_acc = 0.0, 0.0\n",
    "    running_loss,running_acc = 0.0, 0.0\n",
    "    last_loss, last_acc = 0.0, 0.0\n",
    "\n",
    "    START_TIME = time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        sum_loss += loss\n",
    "        running_acc += accuracy_score(labels.cpu(), outputs.argmax(dim=1).cpu())\n",
    "        sum_acc += accuracy_score(labels.cpu(), outputs.argmax(dim=1).cpu())\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss/10\n",
    "            last_acc = running_acc/10\n",
    "            # print(f' - Batch {i+1} loss: {last_loss:.4f} / accuracy: {last_acc:.4f}')\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "    END_TIME = time()\n",
    "\n",
    "    return sum_loss/(i + 1), sum_acc/(i + 1), (END_TIME-START_TIME)\n",
    "\n",
    "def reset_folder():\n",
    "    shutil.rmtree(\"./weights\")\n",
    "    shutil.rmtree(\"./runs\")\n",
    "    os.makedirs(\"./weights\")\n",
    "    os.makedirs(\"./runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## start warm up\n",
      "## finished warm up\n",
      "EPOCH 1: Train Loss: 11.7924 / Valid Loss: 23.9194 / Train Accuracy: 0.0000 / Valid Accuracy: 0.0000 --- (0.2806 sec)\n",
      "EPOCH 2: Train Loss: 9.4871 / Valid Loss: 20.6082 / Train Accuracy: 0.0000 / Valid Accuracy: 0.0000 --- (0.2668 sec)\n",
      "EPOCH 3: Train Loss: 8.3356 / Valid Loss: 17.5929 / Train Accuracy: 0.0143 / Valid Accuracy: 0.0000 --- (0.2812 sec)\n",
      "EPOCH 4: Train Loss: 6.9211 / Valid Loss: 15.4172 / Train Accuracy: 0.1286 / Valid Accuracy: 0.0000 --- (0.2832 sec)\n",
      "EPOCH 5: Train Loss: 6.1730 / Valid Loss: 13.7006 / Train Accuracy: 0.1429 / Valid Accuracy: 0.0333 --- (0.2675 sec)\n",
      "EPOCH 6: Train Loss: 5.9271 / Valid Loss: 13.2184 / Train Accuracy: 0.1857 / Valid Accuracy: 0.0333 --- (0.2855 sec)\n",
      "EPOCH 7: Train Loss: 5.0575 / Valid Loss: 11.6009 / Train Accuracy: 0.2286 / Valid Accuracy: 0.0000 --- (0.2834 sec)\n",
      "EPOCH 8: Train Loss: 4.1342 / Valid Loss: 10.7698 / Train Accuracy: 0.3714 / Valid Accuracy: 0.0333 --- (0.2816 sec)\n",
      "EPOCH 9: Train Loss: 3.4373 / Valid Loss: 9.2313 / Train Accuracy: 0.3000 / Valid Accuracy: 0.0333 --- (0.2700 sec)\n",
      "EPOCH 10: Train Loss: 3.3517 / Valid Loss: 9.1414 / Train Accuracy: 0.3857 / Valid Accuracy: 0.0333 --- (0.2710 sec)\n",
      "EPOCH 11: Train Loss: 2.8124 / Valid Loss: 8.9715 / Train Accuracy: 0.4714 / Valid Accuracy: 0.0000 --- (0.2692 sec)\n",
      "EPOCH 12: Train Loss: 2.2828 / Valid Loss: 8.8710 / Train Accuracy: 0.6000 / Valid Accuracy: 0.0000 --- (0.2646 sec)\n",
      "EPOCH 13: Train Loss: 2.3806 / Valid Loss: 9.5130 / Train Accuracy: 0.4571 / Valid Accuracy: 0.0333 --- (0.2683 sec)\n",
      "EPOCH 14: Train Loss: 2.4323 / Valid Loss: 8.6439 / Train Accuracy: 0.5000 / Valid Accuracy: 0.0667 --- (0.2781 sec)\n",
      "EPOCH 15: Train Loss: 1.7855 / Valid Loss: 6.7452 / Train Accuracy: 0.6286 / Valid Accuracy: 0.0667 --- (0.2684 sec)\n",
      "EPOCH 16: Train Loss: 1.9587 / Valid Loss: 7.0782 / Train Accuracy: 0.5429 / Valid Accuracy: 0.1000 --- (0.2743 sec)\n",
      "EPOCH 17: Train Loss: 2.0757 / Valid Loss: 6.5917 / Train Accuracy: 0.4571 / Valid Accuracy: 0.1000 --- (0.2679 sec)\n",
      "EPOCH 18: Train Loss: 1.6626 / Valid Loss: 6.9388 / Train Accuracy: 0.6143 / Valid Accuracy: 0.1000 --- (0.2850 sec)\n",
      "EPOCH 19: Train Loss: 2.2730 / Valid Loss: 6.9905 / Train Accuracy: 0.5286 / Valid Accuracy: 0.1333 --- (0.2839 sec)\n",
      "EPOCH 20: Train Loss: 2.0266 / Valid Loss: 7.1289 / Train Accuracy: 0.5429 / Valid Accuracy: 0.1333 --- (0.2823 sec)\n",
      "EPOCH 21: Train Loss: 1.6071 / Valid Loss: 8.5083 / Train Accuracy: 0.5714 / Valid Accuracy: 0.1333 --- (0.2856 sec)\n",
      "EPOCH 22: Train Loss: 1.1539 / Valid Loss: 8.4104 / Train Accuracy: 0.7143 / Valid Accuracy: 0.1333 --- (0.2795 sec)\n",
      "EPOCH 23: Train Loss: 1.3902 / Valid Loss: 7.8453 / Train Accuracy: 0.6857 / Valid Accuracy: 0.1667 --- (0.2665 sec)\n",
      "EPOCH 24: Train Loss: 1.4611 / Valid Loss: 8.1248 / Train Accuracy: 0.6000 / Valid Accuracy: 0.1000 --- (0.2665 sec)\n",
      "EPOCH 25: Train Loss: 1.3401 / Valid Loss: 8.2013 / Train Accuracy: 0.6286 / Valid Accuracy: 0.1333 --- (0.2661 sec)\n",
      "EPOCH 26: Train Loss: 1.3778 / Valid Loss: 7.1690 / Train Accuracy: 0.6429 / Valid Accuracy: 0.2000 --- (0.2770 sec)\n",
      "EPOCH 27: Train Loss: 1.4155 / Valid Loss: 7.4254 / Train Accuracy: 0.6000 / Valid Accuracy: 0.2333 --- (0.2666 sec)\n",
      "EPOCH 28: Train Loss: 1.0958 / Valid Loss: 7.9161 / Train Accuracy: 0.7143 / Valid Accuracy: 0.2000 --- (0.2665 sec)\n",
      "EPOCH 29: Train Loss: 1.4617 / Valid Loss: 7.9851 / Train Accuracy: 0.6857 / Valid Accuracy: 0.2333 --- (0.2666 sec)\n",
      "EPOCH 30: Train Loss: 0.9438 / Valid Loss: 7.5873 / Train Accuracy: 0.8000 / Valid Accuracy: 0.3000 --- (0.2577 sec)\n",
      "EPOCH 31: Train Loss: 1.1047 / Valid Loss: 6.8560 / Train Accuracy: 0.6714 / Valid Accuracy: 0.2333 --- (0.2667 sec)\n",
      "EPOCH 32: Train Loss: 1.3577 / Valid Loss: 6.9133 / Train Accuracy: 0.6714 / Valid Accuracy: 0.2000 --- (0.2889 sec)\n",
      "EPOCH 33: Train Loss: 1.4349 / Valid Loss: 6.5401 / Train Accuracy: 0.7143 / Valid Accuracy: 0.1667 --- (0.2540 sec)\n",
      "EPOCH 34: Train Loss: 1.3935 / Valid Loss: 7.1202 / Train Accuracy: 0.6286 / Valid Accuracy: 0.1333 --- (0.2812 sec)\n",
      "EPOCH 35: Train Loss: 1.0329 / Valid Loss: 6.5607 / Train Accuracy: 0.7000 / Valid Accuracy: 0.2000 --- (0.2536 sec)\n",
      "EPOCH 36: Train Loss: 0.8322 / Valid Loss: 7.0493 / Train Accuracy: 0.7714 / Valid Accuracy: 0.2000 --- (0.2511 sec)\n",
      "EPOCH 37: Train Loss: 0.8916 / Valid Loss: 6.2963 / Train Accuracy: 0.7000 / Valid Accuracy: 0.2333 --- (0.2691 sec)\n",
      "EPOCH 38: Train Loss: 0.9966 / Valid Loss: 6.1698 / Train Accuracy: 0.7429 / Valid Accuracy: 0.2000 --- (0.2666 sec)\n",
      "EPOCH 39: Train Loss: 0.8375 / Valid Loss: 6.0810 / Train Accuracy: 0.7429 / Valid Accuracy: 0.3333 --- (0.2667 sec)\n",
      "EPOCH 40: Train Loss: 1.2670 / Valid Loss: 7.1638 / Train Accuracy: 0.7429 / Valid Accuracy: 0.1333 --- (0.2665 sec)\n",
      "EPOCH 41: Train Loss: 1.1207 / Valid Loss: 7.1593 / Train Accuracy: 0.6286 / Valid Accuracy: 0.1667 --- (0.2692 sec)\n",
      "EPOCH 42: Train Loss: 0.6905 / Valid Loss: 6.4816 / Train Accuracy: 0.7571 / Valid Accuracy: 0.1667 --- (0.2669 sec)\n",
      "EPOCH 43: Train Loss: 0.9242 / Valid Loss: 7.0171 / Train Accuracy: 0.7857 / Valid Accuracy: 0.1667 --- (0.2475 sec)\n",
      "EPOCH 44: Train Loss: 0.7275 / Valid Loss: 5.3896 / Train Accuracy: 0.7143 / Valid Accuracy: 0.3000 --- (0.2688 sec)\n",
      "EPOCH 45: Train Loss: 0.8202 / Valid Loss: 5.8362 / Train Accuracy: 0.7714 / Valid Accuracy: 0.2333 --- (0.2667 sec)\n",
      "EPOCH 46: Train Loss: 0.8688 / Valid Loss: 6.4332 / Train Accuracy: 0.6857 / Valid Accuracy: 0.2000 --- (0.2696 sec)\n",
      "EPOCH 47: Train Loss: 0.9649 / Valid Loss: 6.0135 / Train Accuracy: 0.7857 / Valid Accuracy: 0.2667 --- (0.2729 sec)\n",
      "EPOCH 48: Train Loss: 1.3191 / Valid Loss: 5.7453 / Train Accuracy: 0.6000 / Valid Accuracy: 0.1667 --- (0.2727 sec)\n",
      "EPOCH 49: Train Loss: 1.0655 / Valid Loss: 5.2184 / Train Accuracy: 0.7714 / Valid Accuracy: 0.2667 --- (0.2666 sec)\n",
      "EPOCH 50: Train Loss: 0.9650 / Valid Loss: 4.7352 / Train Accuracy: 0.7571 / Valid Accuracy: 0.3333 --- (0.2658 sec)\n",
      "== Total time: 13.5422 sec ==\n"
     ]
    }
   ],
   "source": [
    "reset_folder()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'runs/resnet18_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "total_time = 0\n",
    "EPOCHS = 30\n",
    "best_vloss = 1_000_000.0\n",
    "\n",
    "# warm up \n",
    "print(f'## start warm up')\n",
    "dummy_data = torch.randn(5, 3, 32, 32).to(device)\n",
    "for _ in range(500):\n",
    "    _ = model(dummy_data)\n",
    "print(f'## finished warm up')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number+1}: ', end=\"\")\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, avg_acc, train_time = train_one_epoch(epoch_number, writer)\n",
    "    total_time += train_time\n",
    "\n",
    "    # Set the model to evaluation model\n",
    "    model.eval()\n",
    "    sum_vloss = 0.0\n",
    "    sum_vacc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(valid_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels) # current batch valid loss\n",
    "            vacc = accuracy_score(vlabels.cpu(), voutputs.argmax(dim=1).cpu()) # current batch valid accuracy\n",
    "            sum_vloss += vloss.item() # running_vloss\n",
    "            sum_vacc += vacc # running_vacc\n",
    "\n",
    "    avg_vloss = sum_vloss / (i + 1)\n",
    "    avg_vacc = sum_vacc / (i + 1)\n",
    "    print(f'Train Loss: {avg_loss:.4f} / Valid Loss: {avg_vloss:.4f} / '\n",
    "          f'Train Accuracy: {avg_acc:.4f} / Valid Accuracy: {avg_vacc:.4f} --- ({train_time:.4f} sec)')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalars('Training vs. Validation Accuracy', \n",
    "                    { 'Training' : avg_acc, 'Validation': avg_vacc},\n",
    "                    epoch_number + 1)\n",
    "    writer.flush() # immediately write into file\n",
    " \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_model = model\n",
    "        best_vloss = avg_vloss\n",
    "\n",
    "    epoch_number += 1\n",
    "\n",
    "print(f'== Total time: {total_time:.4f} sec ==')\n",
    "model_path = f'weights/Resnet18_{timestamp}_{epoch_number}.pth'\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a saved version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = r\"models\\model_renet18_.pth\"\n",
    "# saved_model = models.resnet18()\n",
    "# saved_model.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
